{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "# read data\n",
    "df_regular = pd.read_csv(\"2021-2022 NBA Player Stats - Regular.csv\",encoding='latin-1', delimiter=\";\")\n",
    "df_playoffs = pd.read_csv(\"2021-2022 NBA Player Stats - Playoffs.csv\",encoding='latin-1', delimiter=\";\")\n",
    "\n",
    "# rename columns for better interpretability.  Took directly from kaggle dataset page.\n",
    "\n",
    "def rename_columns(df):\n",
    "    df.rename(columns={'Rk' : 'Rank', 'Player' : 'Players_name', 'Pos' : 'Position', 'Age' : 'Players_age', 'Tm' : 'Team', 'G' : 'Games_played', 'GS' : 'Games_started', 'MP' : 'Minutes_played_per_game', 'FG' : 'Field_goals_per_game', 'FGA' : 'Field_goal_attempts_per_game', 'FG%' : 'Field_goal_percentage', '3P' : '3_point_field_goals_per_game', '3PA' : '3_point_field_goal_attempts_per_game', '3P%' : '3_point_field_goal_percentage', '2P' : '2_point_field_goals_per_game', '2PA' : '2_point_field_goal_attempts_per_game', '2P%' : '2_point_field_goal_percentage', 'eFG%' : 'Effective_field_goal_percentage', 'FT' : 'Free_throws_per_game', 'FTA' : 'Free_throw_attempts_per_game', 'FT%' : 'Free_throw_percentage', 'ORB' : 'Offensive_rebounds_per_game', 'DRB' : 'Defensive_rebounds_per_game', 'TRB' : 'Total_rebounds_per_game', 'AST' : 'Assists_per_game', 'STL' : 'Steals_per_game', 'BLK' : 'Blocks_per_game', 'TOV' : 'Turnovers_per_game', 'PF' : 'Personal_fouls_per_game', 'PTS' : 'Points_per_game'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "df_regular = rename_columns(df_regular)\n",
    "df_playoffs = rename_columns(df_playoffs)\n",
    "# convert position column to only have guard, forward, and center (3 classes)\n",
    "\n",
    "def convert_position(df):\n",
    "    df['Class'] = df['Position'].map({'SG': 'Guard','SF' : 'Forward', 'PG' : 'Guard', 'PF' : 'Forward', 'C' : 'Center','SG-SF' : 'Guard', 'SF-SG' : 'Forward', 'SG-PG' : 'Guard', 'C-PF' : 'Center', 'PF-SF' : 'Forward', 'PG-SG' : 'Guard'})\n",
    "    df.drop(columns=['Position'], inplace=True)\n",
    "    return df\n",
    "\n",
    "df_regular = convert_position(df_regular)\n",
    "df_playoffs = convert_position(df_playoffs)\n",
    "# encode class column as numeric using LabelEncoder\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "df_regular['Class'] = le.fit_transform(df_regular['Class'])\n",
    "df_playoffs['Class'] = le.fit_transform(df_playoffs['Class'])\n",
    "# create extra features.  My hopethesis is that the ratios of some statistics relative to the sum of those stats might be more predictive than the absolute stats in certain instances.  I've followed basketball (and played) my entire life so my intuition is that we can use these ratios to predict a player's position.\n",
    "\n",
    "# df_regular['Total_stats'] = df_regular['Points_per_game'] + df_regular['Total_rebounds_per_game'] + df_regular['Assists_per_game'] + df_regular['Steals_per_game'] + df_regular['Blocks_per_game'] + df_regular['Turnovers_per_game'] + df_regular['3_point_field_goals_per_game']\n",
    "\n",
    "# df_regular['Total_stats'].describe()\n",
    "# df_regular[df_regular.Total_stats == 0]\n",
    "\n",
    "# df_regular['Points_per_game_percentage'] = df_regular['Points_per_game'] / df_regular['Total_stats']\n",
    "# df_regular['Total_rebounds_per_game_percentage'] = df_regular['Total_rebounds_per_game'] / df_regular['Total_stats']\n",
    "# df_regular['Assists_per_game_percentage'] = df_regular['Assists_per_game'] / df_regular['Total_stats']\n",
    "# df_regular['Steals_per_game_percentage'] = df_regular['Steals_per_game'] / df_regular['Total_stats']\n",
    "# df_regular['Blocks_per_game_percentage'] = df_regular['Blocks_per_game'] / df_regular['Total_stats']\n",
    "# df_regular['Turnovers_per_game_percentage'] = df_regular['Turnovers_per_game'] / df_regular['Total_stats']\n",
    "# df_regular['3_point_field_goals_per_game_percentage'] = df_regular['3_point_field_goals_per_game'] / df_regular['Total_stats']\n",
    "\n",
    "# df_regular = df_regular[df_regular['Total_stats'] != 0]\n",
    "\n",
    "# # create the same extra features for the playoffs dataset\n",
    "\n",
    "# df_playoffs['Total_stats'] = df_playoffs['Points_per_game'] + df_playoffs['Total_rebounds_per_game'] + df_playoffs['Assists_per_game'] + df_playoffs['Steals_per_game'] + df_playoffs['Blocks_per_game'] + df_playoffs['Turnovers_per_game'] + df_playoffs['3_point_field_goals_per_game']\n",
    "\n",
    "# df_playoffs['Points_per_game_percentage'] = df_playoffs['Points_per_game'] / df_playoffs['Total_stats']\n",
    "# df_playoffs['Total_rebounds_per_game_percentage'] = df_playoffs['Total_rebounds_per_game'] / df_playoffs['Total_stats']\n",
    "# df_playoffs['Assists_per_game_percentage'] = df_playoffs['Assists_per_game'] / df_playoffs['Total_stats']\n",
    "# df_playoffs['Steals_per_game_percentage'] = df_playoffs['Steals_per_game'] / df_playoffs['Total_stats']\n",
    "# df_playoffs['Blocks_per_game_percentage'] = df_playoffs['Blocks_per_game'] / df_playoffs['Total_stats']\n",
    "# df_playoffs['Turnovers_per_game_percentage'] = df_playoffs['Turnovers_per_game'] / df_playoffs['Total_stats']\n",
    "# df_playoffs['3_point_field_goals_per_game_percentage'] = df_playoffs['3_point_field_goals_per_game'] / df_playoffs['Total_stats']\n",
    "\n",
    "# df_playoffs = df_playoffs[df_playoffs['Total_stats'] != 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regular['2_point_vs_3_point_attempts'] = df_regular['2_point_field_goals_per_game'].div(df_regular['3_point_field_goal_attempts_per_game'].values, fill_value=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use minmax scaler to scale the following columns: Defensive Rebounds, Steals, Blocks\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_regular['Defensive_rebounds_per_game'] = scaler.fit_transform(df_regular[['Defensive_rebounds_per_game']])\n",
    "df_regular['Steals_per_game'] = scaler.fit_transform(df_regular[['Steals_per_game']])\n",
    "df_regular['Blocks_per_game'] = scaler.fit_transform(df_regular[['Blocks_per_game']])\n",
    "\n",
    "# sum the three scaled columns to create a new column called 'Defensive_stats'\n",
    "\n",
    "df_regular['Defensive_stats'] = df_regular['Defensive_rebounds_per_game'] + df_regular['Steals_per_game'] + df_regular['Blocks_per_game']\n",
    "\n",
    "# get the percentage of the three scaled columns relative to the sum of the three scaled columns\n",
    "\n",
    "df_regular['Defensive_rebounds_per_game_percentage'] = df_regular['Defensive_rebounds_per_game'] / df_regular['Defensive_stats']\n",
    "df_regular['Steals_per_game_percentage'] = df_regular['Steals_per_game'] / df_regular['Defensive_stats']\n",
    "df_regular['Blocks_per_game_percentage'] = df_regular['Blocks_per_game'] / df_regular['Defensive_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the same process for the following columns Assists, Offensive_Rebounds,Turnovers, 3_point_field_goals\n",
    "\n",
    "df_regular['Assists_per_game'] = scaler.fit_transform(df_regular[['Assists_per_game']])\n",
    "df_regular['Offensive_rebounds_per_game'] = scaler.fit_transform(df_regular[['Offensive_rebounds_per_game']])\n",
    "df_regular['Turnovers_per_game'] = scaler.fit_transform(df_regular[['Turnovers_per_game']])\n",
    "df_regular['3_point_field_goals_per_game'] = scaler.fit_transform(df_regular[['3_point_field_goals_per_game']])\n",
    "df_regular['Offensive_stats'] = df_regular['Assists_per_game'] + df_regular['Offensive_rebounds_per_game'] + df_regular['Turnovers_per_game'] + df_regular['3_point_field_goals_per_game']\n",
    "\n",
    "# get the percentage of the four scaled columns relative to the sum of the four scaled columns\n",
    "\n",
    "df_regular['Assists_per_game_percentage'] = df_regular['Assists_per_game'] / df_regular['Offensive_stats']\n",
    "df_regular['Offensive_rebounds_per_game_percentage'] = df_regular['Offensive_rebounds_per_game'] / df_regular['Offensive_stats']\n",
    "df_regular['Turnovers_per_game_percentage'] = df_regular['Turnovers_per_game'] / df_regular['Offensive_stats']\n",
    "df_regular['3_point_field_goals_per_game_percentage'] = df_regular['3_point_field_goals_per_game'] / df_regular['Offensive_stats']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace inf values with missing values for the new columns\n",
    "\n",
    "df_regular.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37 numeric columns and 0 categorical columns\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split data into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_regular.drop(columns=['Class'])\n",
    "y = df_regular['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# separate categorical columns from numeric\n",
    "passthrough = ['Players_name', 'Team']\n",
    "X_train.drop(columns=passthrough, inplace=True)\n",
    "X_test.drop(columns=passthrough, inplace=True)\n",
    "mask = X_train.dtypes == 'object'\n",
    "categorical = X_train.columns[mask]\n",
    "numeric = X_train.columns[~mask]\n",
    "\n",
    "print('There are {} numeric columns and {} categorical columns'.format(len(numeric), len(categorical)))\n",
    "\n",
    "# create new X_train with only the new columns\n",
    "\n",
    "new_features = ['Defensive_rebounds_per_game_percentage', 'Steals_per_game_percentage', 'Blocks_per_game_percentage', 'Assists_per_game_percentage', 'Offensive_rebounds_per_game_percentage', 'Turnovers_per_game_percentage', '3_point_field_goals_per_game_percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 categorical columns in X_train\n",
      "Accuracy score: 0.7791411042944786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vpittamp/ls/envs/cs109a_finalproj/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# create a logistic regression pipeline using only the new_features with a column transformer and a logistic regression classifier and impute missing values and infinities\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# how many categorical columns are there in X_train?\n",
    "print('There are {} categorical columns in X_train'.format(len(categorical)))\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric),\n",
    "        ('cat', categorical_transformer, categorical)])\n",
    "        \n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', LogisticRegression())])\n",
    "\n",
    "# fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print the accuracy score\n",
    "print('Accuracy score: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 feature  coefficient\n",
      "4                Minutes_played_per_game    -1.694657\n",
      "21                      Assists_per_game    -1.268568\n",
      "19           Defensive_rebounds_per_game     0.824962\n",
      "20               Total_rebounds_per_game     0.780394\n",
      "12  2_point_field_goal_attempts_per_game    -0.764404\n",
      "6           Field_goal_attempts_per_game    -0.707078\n",
      "11          2_point_field_goals_per_game     0.643750\n",
      "8           3_point_field_goals_per_game     0.564947\n",
      "5                   Field_goals_per_game     0.542063\n",
      "9   3_point_field_goal_attempts_per_game    -0.464601\n"
     ]
    }
   ],
   "source": [
    "# get the most important features using the coefficients of the logistic regression model\n",
    "\n",
    "# get the coefficients of the logistic regression model\n",
    "coefficients = clf.named_steps['classifier'].coef_[0]\n",
    "\n",
    "# get the feature names\n",
    "feature_names = clf.named_steps['preprocessor'].transformers_[0][2]\n",
    "\n",
    "# create a dataframe with the coefficients and feature names\n",
    "df_coefficients = pd.DataFrame({'feature': feature_names, 'coefficient': coefficients})\n",
    "\n",
    "# sort the dataframe by the absolute value of the coefficients\n",
    "df_coefficients = df_coefficients.sort_values(by='coefficient', key=abs, ascending=False)\n",
    "\n",
    "# print the top 10 features\n",
    "print(df_coefficients.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'C' for estimator Pipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  Index(['Rank', 'Players_age', 'Games_played', 'Games_started',\n       'Minutes_played_per_game', 'Field_goals_per_game',\n       'Field_goal_attempts_per_game', 'Field_goal_percentage',\n       '3_point_field_goals_per_...\n       'Assists_per_game_percentage', 'Offensive_rebounds_per_game_percentage',\n       'Turnovers_per_game_percentage',\n       '3_point_field_goals_per_game_percentage'],\n      dtype='object')),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(fill_value='missing',\n                                                                                 strategy='constant')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n                                                  Index([], dtype='object'))])),\n                ('classifier', LogisticRegression(max_iter=10000))]). Valid parameters are: ['memory', 'steps', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [88], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(clf, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, return_train_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m \u001b[39m# fit the grid search model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m grid\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     15\u001b[0m \u001b[39m# print the best parameters\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest parameters: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(grid\u001b[39m.\u001b[39mbest_params_))\n",
      "File \u001b[0;32m~/ls/envs/cs109a_finalproj/lib/python3.11/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/ls/envs/cs109a_finalproj/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1389\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1388\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1389\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/ls/envs/cs109a_finalproj/lib/python3.11/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/ls/envs/cs109a_finalproj/lib/python3.11/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/ls/envs/cs109a_finalproj/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/ls/envs/cs109a_finalproj/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/ls/envs/cs109a_finalproj/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/ls/envs/cs109a_finalproj/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/ls/envs/cs109a_finalproj/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[0;32m~/ls/envs/cs109a_finalproj/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/ls/envs/cs109a_finalproj/lib/python3.11/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/ls/envs/cs109a_finalproj/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:674\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m parameters\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    672\u001b[0m         cloned_parameters[k] \u001b[39m=\u001b[39m clone(v, safe\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 674\u001b[0m     estimator \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39;49mset_params(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcloned_parameters)\n\u001b[1;32m    676\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    678\u001b[0m X_train, y_train \u001b[39m=\u001b[39m _safe_split(estimator, X, y, train)\n",
      "File \u001b[0;32m~/ls/envs/cs109a_finalproj/lib/python3.11/site-packages/sklearn/pipeline.py:212\u001b[0m, in \u001b[0;36mPipeline.set_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_params\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    194\u001b[0m     \u001b[39m\"\"\"Set the parameters of this estimator.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \n\u001b[1;32m    196\u001b[0m \u001b[39m    Valid parameter keys can be listed with ``get_params()``. Note that\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39m        Pipeline class instance.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_params(\u001b[39m\"\u001b[39;49m\u001b[39msteps\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/ls/envs/cs109a_finalproj/lib/python3.11/site-packages/sklearn/utils/metaestimators.py:70\u001b[0m, in \u001b[0;36m_BaseComposition._set_params\u001b[0;34m(self, attr, **params)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_replace_estimator(attr, name, params\u001b[39m.\u001b[39mpop(name))\n\u001b[1;32m     69\u001b[0m \u001b[39m# 3. Step parameters and other initialisation arguments\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mset_params(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m     71\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/ls/envs/cs109a_finalproj/lib/python3.11/site-packages/sklearn/base.py:205\u001b[0m, in \u001b[0;36mBaseEstimator.set_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m valid_params:\n\u001b[1;32m    204\u001b[0m     local_valid_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_param_names()\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid parameter \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m!r}\u001b[39;00m\u001b[39m for estimator \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValid parameters are: \u001b[39m\u001b[39m{\u001b[39;00mlocal_valid_params\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    210\u001b[0m \u001b[39mif\u001b[39;00m delim:\n\u001b[1;32m    211\u001b[0m     nested_params[key][sub_key] \u001b[39m=\u001b[39m value\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter 'C' for estimator Pipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  Index(['Rank', 'Players_age', 'Games_played', 'Games_started',\n       'Minutes_played_per_game', 'Field_goals_per_game',\n       'Field_goal_attempts_per_game', 'Field_goal_percentage',\n       '3_point_field_goals_per_...\n       'Assists_per_game_percentage', 'Offensive_rebounds_per_game_percentage',\n       'Turnovers_per_game_percentage',\n       '3_point_field_goals_per_game_percentage'],\n      dtype='object')),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(fill_value='missing',\n                                                                                 strategy='constant')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n                                                  Index([], dtype='object'))])),\n                ('classifier', LogisticRegression(max_iter=10000))]). Valid parameters are: ['memory', 'steps', 'verbose']."
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('cs109a_finalproj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31a55d9ebe46a8e5493501d129b9c99fc33e91cb8594a70fee0536f8269e5c51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
